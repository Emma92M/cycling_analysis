# Cycling Data Scraper

## Project Description

This part of Python project automates the downloading and processing of cycling data from the Transport for London (TfL) cycling data API. It is designed to fetch files listed in a text file, download them to a specified directory, and then combine all CSV files for each year into a single CSV file for easy analysis.
The project involves a detailed examination of cycling usage statistics, offering insights into trends, patterns, and behaviors among cyclists. The notebook includes data cleaning, manipulation, visualization, and analysis steps to derive meaningful information from the dataset.

## Features

- Downloads cycling data files from TfL's API.
- Organizes files by year.
- Combines all CSV files for each year into a single file.
- Data Importing: Load cycling data from various CSV files.
- Data Cleaning: Handle missing values, outliers, and data inconsistencies.
- Data Analysis: Analyze the dataset to uncover trends and patterns.
- Data Visualization: Visualize the data using various graphs and charts for better understanding.

## Requirements

- Python 3.x
- Pandas library
- Requests library

## Installation

To set up the project environment:

1. Ensure Python 3.x is installed on your system.
2. Install required Python libraries:
   ```
   pip install pandas requests
   ```

## Usage

1. Clone the repository:
   ```
   git clone [repository_url]
   ```
2. Navigate to the project directory.
3. Modify the `base_url`, `base_directory`, and `file_list_path` in the script to point to the appropriate API endpoint, local directory for storing files, and the text file containing the list of files to download.
4. Run the script:
   ```
   python cycling_data.py
   ```

## Configuration

- `base_url`: URL of the cycling data API.
- `base_directory`: Local directory path to store downloaded files.
- `file_list_path`: Path to the text file containing the list of filenames to download.

