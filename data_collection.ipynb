{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPnDewV+8hsiEgGlzdOyyVu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data Collection"],"metadata":{"id":"fUhN5NhjR1dC"}},{"cell_type":"code","source":["import os\n","import requests\n","\n","# Base URL\n","base_url = \"https://cycling.data.tfl.gov.uk/usage-stats/\"\n","\n","# Directory to store the files\n","base_directory =\"/content/drive/MyDrive/cycling\"\n","\n","# Path to the text file containing filenames\n","file_path = '/content/drive/MyDrive/cycling/files.txt'\n","\n","def download_file(url, folder, filename):\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        with open(os.path.join( 'wb') as f:\n","            f.write(response.content)\n","\n","with open(file_path, 'r') as file:\n","    filenames = [line.strip() for line in file]\n","\n","# Process each filename\n","for filename in filenames:\n","    year = filename[-8:-4]\n","\n","    # Create directory for the year\n","    year_dir = os.path.join(base_directory, year)\n","    os.makedirs(year_dir, exist_ok=True)\n","    file_url = base_url + filename\n","\n","    print(f\"Downloading {filename}...\")\n","    download_file(file_url, year_dir, filename)"],"metadata":{"id":"EWI-UmMXR0Rg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","base_directory = \"/content/drive/MyDrive/cycling\"\n","\n","# List all year directories\n","year_dirs = [dir for dir in os.listdir(base_directory) if os.path.isdir(os.path.join(base_directory, dir))]\n","\n","\n","for year_dir in year_dirs:\n","    combined_df = pd.DataFrame()\n","\n","    # Path to the current year directory\n","    current_dir = os.path.join(base_directory, year_dir)\n","\n","    # Iterate through all CSV files in the directory\n","    for file in os.listdir(current_dir):\n","        if file.endswith('.csv'):\n","            file_path = os.path.join(current_dir, file)\n","            df = pd.read_csv(file_path)\n","            combined_df = pd.concat([combined_df, df])\n","\n","    # Save the combined DataFrame to a CSV file\n","    combined_df.to_csv(os.path.join(current_dir, f'all_data_{year_dir}.csv'), index=False)\n","\n"],"metadata":{"id":"DbS0QVozSJBM"},"execution_count":null,"outputs":[]}]}